#!/usr/bin/env python3
"""
NYC Open Data Dignity Lens Content Generator
Automatically generates systematic racism analysis using real NYC data,
including borough/neighborhood/council field mapping and NYC-specific power mapping.
"""

import requests
import os
import json
from datetime import datetime, timedelta
from anthropic import Anthropic
import time
import pandas as pd
from typing import Dict, List, Optional, Any
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Initialize Claude API
client = Anthropic(api_key=os.environ.get('CLAUDE_API_KEY'))

def get_geographic_field(df, possible_fields):
    """
    Returns the first matching geographic field from the dataframe.
    Example possible_fields: ['borough', 'boro_nm', 'arrest_boro', 'BOROUGH', 'boro']
    """
    for field in possible_fields:
        if field in df.columns:
            return field
    return None

class NYCDataAnalyzer:
    """Analyzes NYC open data through the Dignity Lens framework"""

    NYC_DATA_ENDPOINTS = {
        'police_incidents': {
            'url': 'https://data.cityofnewyork.us/resource/qb7u-rbmr.json',
            'description': 'NYPD Police Incident Data',
            'dignity_focus': 'Legal System & Mass Incarceration'
        },
        'building_violations': {
            'url': 'https://data.cityofnewyork.us/resource/3h2n-5cm9.json',
            'description': 'DOB Building Violations',
            'dignity_focus': 'Housing & Community Development'
        },
        'school_performance': {
            'url': 'https://data.cityofnewyork.us/resource/uq7m-95z8.json',
            'description': 'NYC School Quality Reports',
            'dignity_focus': 'Education & School-to-Prison Pipeline'
        },
        'public_health': {
            'url': 'https://data.cityofnewyork.us/resource/w3tr-8p7e.json',
            'description': 'Community Health Profiles',
            'dignity_focus': 'Medical Racism & Community Health'
        },
        'business_licenses': {
            'url': 'https://data.cityofnewyork.us/resource/nc67-uf89.json',
            'description': 'Active Business Licenses',
            'dignity_focus': 'Economic Exclusion & Community Wealth Building'
        },
        'affordable_housing': {
            'url': 'https://data.cityofnewyork.us/resource/4v2b-8cgt.json',
            'description': 'Affordable Housing Production by Project',
            'dignity_focus': 'Housing & Community Development'
        },
        'environmental_health': {
            'url': 'https://data.cityofnewyork.us/resource/6fi9-q3ta.json',
            'description': 'Environmental Public Health Tracking',
            'dignity_focus': 'Environmental Racism & Community Health'
        },
        'neighborhoods': {
            'url': 'https://data.cityofnewyork.us/resource/cpf4-rkhq.json',
            'description': 'NYC Neighborhood Tabulation Areas',
            'dignity_focus': 'Power Structures Domain'
        },
        'city_budget': {
            'url': 'https://data.cityofnewyork.us/resource/jb7j-dtam.json',
            'description': 'NYC Expense Budget',
            'dignity_focus': 'Government Systems & Political Exclusion'
        },
        'mta_ridership': {
            'url': 'https://data.ny.gov/resource/ivw2-k53g.json',
            'description': 'MTA Subway Turnstile Data',
            'dignity_focus': 'Transportation Justice'
        }
    }

    def __init__(self):
        self.nyc_app_token = os.environ.get('NYC_DATA_TOKEN')  # Optional but recommended

    def fetch_dataset(self, endpoint_key: str, limit: int = 1000, **filters) -> List[Dict]:
        """Fetch data from NYC Open Data Portal"""
        if endpoint_key not in self.NYC_DATA_ENDPOINTS:
            raise ValueError(f"Unknown endpoint: {endpoint_key}")

        endpoint = self.NYC_DATA_ENDPOINTS[endpoint_key]
        url = endpoint['url']

        params = {'$limit': limit}
        if self.nyc_app_token:
            params['$$app_token'] = self.nyc_app_token
        params.update(filters)

        try:
            logger.info(f"Fetching {endpoint_key} data from NYC Open Data...")
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            logger.info(f"Retrieved {len(data)} records from {endpoint_key}")
            return data
        except Exception as e:
            logger.error(f"Error fetching {endpoint_key}: {e}")
            return []

    def analyze_racial_disparities(self, data: List[Dict], endpoint_key: str) -> Dict:
        """Analyze disparities in the dataset"""
        if not data:
            return {'error': 'No data available'}
        df = pd.DataFrame(data)
        analysis = {
            'endpoint': endpoint_key,
            'total_records': len(df),
            'date_range': self._get_date_range(df),
            'geographic_distribution': self._analyze_geographic_patterns(df),
            'systematic_patterns': self._identify_systematic_patterns(df, endpoint_key),
            'dignity_lens_application': self._apply_dignity_lens(df, endpoint_key)
        }
        return analysis

    def _get_date_range(self, df: pd.DataFrame) -> Dict:
        date_columns = [col for col in df.columns if 'date' in col.lower() or 'time' in col.lower()]
        if not date_columns:
            return {'note': 'No date columns found'}
        date_col = date_columns[0]
        try:
            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
            return {
                'start_date': df[date_col].min().strftime('%Y-%m-%d') if pd.notna(df[date_col].min()) else 'Unknown',
                'end_date': df[date_col].max().strftime('%Y-%m-%d') if pd.notna(df[date_col].max()) else 'Unknown',
                'date_column': date_col
            }
        except:
            return {'note': 'Could not parse dates'}

    def _analyze_geographic_patterns(self, df: pd.DataFrame) -> Dict:
        borough_field = get_geographic_field(df, ['borough', 'boro_nm', 'arrest_boro', 'BOROUGH', 'boro'])
        nta_field = get_geographic_field(df, ['nta', 'ntaname', 'neighborhood', 'NTAName', 'nta_code'])
        council_field = get_geographic_field(df, ['council_district', 'COUNCIL_DISTRICT', 'council'])
        zip_field = get_geographic_field(df, ['zipcode', 'zip_code', 'ZIP', 'zip'])

        field = borough_field or nta_field or council_field or zip_field
        if not field:
            return {'note': 'No geographic columns found'}

        distribution = df[field].value_counts().to_dict()
        return {
            'primary_geographic_field': field,
            'distribution': distribution,
            'most_affected_areas': list(df[field].value_counts().head(10).index),
            'total_areas': df[field].nunique()
        }

    def _identify_systematic_patterns(self, df: pd.DataFrame, endpoint_key: str) -> Dict:
        patterns = {
            'data_quality': {
                'missing_values': df.isnull().sum().to_dict(),
                'duplicate_records': df.duplicated().sum()
            }
        }
        # Endpoint-specific pattern analysis
        if endpoint_key == 'police_incidents':
            patterns['policing_patterns'] = self._analyze_policing_patterns(df)
        elif endpoint_key == 'building_violations':
            patterns['housing_patterns'] = self._analyze_housing_patterns(df)
        elif endpoint_key == 'school_performance':
            patterns['education_patterns'] = self._analyze_education_patterns(df)
        elif endpoint_key == 'public_health':
            patterns['health_patterns'] = self._analyze_health_patterns(df)
        elif endpoint_key == 'business_licenses':
            patterns['economic_patterns'] = self._analyze_economic_patterns(df)
        return patterns

    def _analyze_policing_patterns(self, df: pd.DataFrame) -> Dict:
        patterns = {}
        if 'ofns_desc' in df.columns:
            patterns['offense_types'] = df['ofns_desc'].value_counts().to_dict()
        if 'arrest_boro' in df.columns:
            patterns['arrest_borough_distribution'] = df['arrest_boro'].value_counts().to_dict()
        if 'boro_nm' in df.columns:
            patterns['borough_distribution'] = df['boro_nm'].value_counts().to_dict()
        return patterns

    def _analyze_housing_patterns(self, df: pd.DataFrame) -> Dict:
        patterns = {}
        if 'violation_category' in df.columns:
            patterns['violation_types'] = df['violation_category'].value_counts().to_dict()
        if 'borough' in df.columns:
            patterns['borough_distribution'] = df['borough'].value_counts().to_dict()
        return patterns

    def _analyze_education_patterns(self, df: pd.DataFrame) -> Dict:
        patterns = {}
        if 'school_name' in df.columns:
            patterns['total_schools'] = df['school_name'].nunique()
        return patterns

    def _analyze_health_patterns(self, df: pd.DataFrame) -> Dict:
        patterns = {}
        if 'borough' in df.columns:
            patterns['borough_distribution'] = df['borough'].value_counts().to_dict()
        return patterns

    def _analyze_economic_patterns(self, df: pd.DataFrame) -> Dict:
        patterns = {}
        if 'industry' in df.columns:
            patterns['industry_types'] = df['industry'].value_counts().to_dict()
        if 'borough' in df.columns:
            patterns['borough_distribution'] = df['borough'].value_counts().to_dict()
        return patterns

    def _apply_dignity_lens(self, df: pd.DataFrame, endpoint_key: str) -> Dict:
        endpoint_info = self.NYC_DATA_ENDPOINTS[endpoint_key]
        return {
            'dignity_focus_area': endpoint_info['dignity_focus'],
            'power_structures_revealed': self._identify_power_structures(df, endpoint_key),
            'control_mechanisms_shown': self._identify_control_mechanisms(df, endpoint_key),
            'community_resistance_opportunities': self._identify_resistance_opportunities(df, endpoint_key),
            'liberation_strategies_suggested': self._suggest_liberation_strategies(df, endpoint_key)
        }

    def _identify_power_structures(self, df: pd.DataFrame, endpoint_key: str) -> List[str]:
        if endpoint_key == 'police_incidents':
            return ['NYPD', 'District Attorneys', 'NYC City Council Public Safety Committee']
        elif endpoint_key == 'building_violations':
            return ['NYC Department of Buildings', 'Property Owners/Landlords', 'Borough Presidents']
        elif endpoint_key == 'school_performance':
            return ['NYC Department of Education', 'Community Education Councils', 'Mayor’s Office']
        elif endpoint_key == 'public_health':
            return ['NYC Department of Health and Mental Hygiene', 'NYC Health + Hospitals']
        elif endpoint_key == 'business_licenses':
            return ['NYC Department of Consumer and Worker Protection', 'City Council', 'Borough Presidents']
        elif endpoint_key == 'mta_ridership':
            return ['MTA Board', 'MTA Chair', 'NYS Governor', 'NYC Council Transportation Committee']
        else:
            return ['NYC government agencies', 'Community stakeholders']

    def _identify_control_mechanisms(self, df: pd.DataFrame, endpoint_key: str) -> List[str]:
        if endpoint_key == 'police_incidents':
            return ['Selective enforcement patterns', 'Geographic concentration of arrests', 'Differential charge severity']
        elif endpoint_key == 'building_violations':
            return ['Unequal code enforcement', 'Delayed repairs in certain neighborhoods', 'Displacement through violation']
        elif endpoint_key == 'school_performance':
            return ['Resource allocation disparities', 'Performance-based school closures', 'Disciplinary disparities']
        elif endpoint_key == 'public_health':
            return ['Health service deserts', 'Environmental health disparities', 'Limited prevention resources']
        elif endpoint_key == 'business_licenses':
            return ['Licensing barriers', 'Unequal business development support', 'Zoning restrictions']
        elif endpoint_key == 'mta_ridership':
            return ['Fare enforcement disparities', 'Service allocation inequities', 'Accessibility gaps']
        else:
            return ['Administrative barriers', 'Resource allocation patterns']

    def _identify_resistance_opportunities(self, df: pd.DataFrame, endpoint_key: str) -> List[str]:
        return [
            'Community data analysis and advocacy',
            'Public records requests for transparency',
            'Community organizing around patterns revealed',
            'Policy advocacy based on data evidence',
            'Coalition building across affected boroughs'
        ]

    def _suggest_liberation_strategies(self, df: pd.DataFrame, endpoint_key: str) -> List[str]:
        if endpoint_key == 'police_incidents':
            return ['Civilian Complaint Review Board advocacy', 'Community oversight boards', 'Restorative justice initiatives']
        elif endpoint_key == 'building_violations':
            return ['Tenant organizing', 'Community land trusts', 'Housing preservation ordinances']
        elif endpoint_key == 'school_performance':
            return ['Community schools model', 'Participatory budgeting', 'Local school councils']
        elif endpoint_key == 'public_health':
            return ['Community health workers', 'Environmental justice organizing', 'Community-controlled health centers']
        elif endpoint_key == 'business_licenses':
            return ['Business incubators', 'Cooperative economics', 'Community development financial institutions']
        elif endpoint_key == 'mta_ridership':
            return ['Fare equity coalitions', 'Transit justice organizing', 'Accessibility task forces']
        else:
            return ['Community-controlled alternatives', 'Policy advocacy', 'Organizing infrastructure']

def create_nypd_power_mapping_prompt(analysis: Dict) -> str:
    return f"""
You are DignityAI creating a POWER MAPPING analysis for NYC organizers focused on NYPD policing data.

DATASET ANALYZED: NYPD Police Incident Data

DATA SUMMARY:
{json.dumps(analysis, indent=2)}

Please create a detailed power map (1000-1200 words) including:

# NYC POWER MAP: NYPD Policing

## Executive Summary: Who Has Power and How to Challenge It

## PRIMARY POWER HOLDERS
- NYPD leadership (Commissioner, Chief of Department)
- Precinct Commanders (especially in most-affected boroughs/neighborhoods)
- NYC Mayor's Office (appoints NYPD Commissioner)
- NYC City Council Public Safety Committee
- District Attorneys for each borough

## COMMUNITY POWER ANALYSIS
- Most affected neighborhoods/boroughs based on data
- Community organizations working on NYPD reform (e.g. Communities United for Police Reform, Justice Committee)
- NYC Civilian Complaint Review Board (CCRB) and its role

## POWER RELATIONSHIPS AND PRESSURE POINTS
- Decision-making and budget cycle for NYPD
- Police union influence (PBA, SBA, etc.)
- Oversight mechanisms (City Council, CCRB, Inspector General)
- Electoral vulnerabilities (Council Members, DAs, Mayor)

## ORGANIZING STRATEGY RECOMMENDATIONS
- Coalition building (cross-borough, cross-racial)
- Policy and budget advocacy (City Council budget hearings, participatory budgeting)
- Campaigns for NYPD transparency, discipline reforms, divest/invest strategies

## TACTICAL POWER ANALYSIS
- Immediate leverage (budget hearings, public testimony)
- Medium term (coalition campaigns, electoral organizing)
- Long term (systemic police accountability, alternative public safety models)

## NYC-SPECIFIC CONSIDERATIONS
- Borough-level organizing (Brooklyn, Bronx, Queens, Manhattan, Staten Island)
- Community Board engagement
- Cross-borough coalition opportunities

## Conclusion: From Power Analysis to Community Power
"""

def create_mta_power_mapping_prompt(analysis: Dict) -> str:
    return f"""
You are DignityAI creating a POWER MAPPING analysis for NYC organizers focused on MTA transit data.

DATASET ANALYZED: MTA Subway Turnstile Data

DATA SUMMARY:
{json.dumps(analysis, indent=2)}

Please create a detailed power map (1000-1200 words) including:

# NYC POWER MAP: MTA Transit

## Executive Summary: Who Has Power and How to Challenge It

## PRIMARY POWER HOLDERS
- MTA Board and Chair
- NYC Mayor and Borough Presidents (appoint MTA board members)
- NYS Governor (appoints MTA Chair, controls funding)
- NYC Council Transportation Committee

## COMMUNITY POWER ANALYSIS
- Most transit-dependent neighborhoods/boroughs based on data
- Transit advocacy groups (e.g. Riders Alliance, Transportation Alternatives)
- Disability and accessibility organizations

## POWER RELATIONSHIPS AND PRESSURE POINTS
- MTA capital plan and budget process
- NYS legislative oversight
- City vs. State control issues
- Fare enforcement and policing

## ORGANIZING STRATEGY RECOMMENDATIONS
- Fare equity campaigns
- Service restoration advocacy
- Accessibility and ADA compliance campaigns
- Budget and funding advocacy at city and state level

## NYC-SPECIFIC CONSIDERATIONS
- Borough-level transit disparities
- Community Board and Council advocacy
- Cross-borough and cross-constituency coalition building

## Conclusion: From Power Analysis to Community Power
"""

def call_claude_api(prompt: str, max_retries: int = 3) -> Optional[str]:
    """Send prompt to Claude API with retry logic"""
    for attempt in range(max_retries):
        try:
            message = client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=4000,
                messages=[{"role": "user", "content": prompt}]
            )
            time.sleep(1.5)
            return message.content[0].text
        except Exception as e:
            logger.error(f"Claude API error (attempt {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                time.sleep(5)
            else:
                return None

def save_content(content: str, content_type: str, dataset_name: str):
    """Save generated content to appropriate folder"""
    if not content:
        return
    os.makedirs(f'drafts/{content_type}', exist_ok=True)
    date_str = datetime.now().strftime('%Y%m%d')
    filename = f'drafts/{content_type}/{date_str}-nyc-{dataset_name}.md'
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(content)
    logger.info(f"✅ Saved: {filename}")

def main():
    """Main content generation function using NYC open data"""
    logger.info("🚀 Starting NYC Open Data Dignity Lens content generation...")
    analyzer = NYCDataAnalyzer()
    priority_datasets = [
        'police_incidents', 'building_violations', 'school_performance',
        'public_health', 'business_licenses', 'affordable_housing',
        'environmental_health', 'neighborhoods', 'city_budget', 'mta_ridership'
    ]
    processed_count = 0
    for dataset_key in priority_datasets:
        logger.info(f"\n📊 Processing {dataset_key}...")
        try:
            data = analyzer.fetch_dataset(dataset_key, limit=1000)
            if not data:
                logger.warning(f"No data retrieved for {dataset_key}")
                continue
            analysis = analyzer.analyze_racial_disparities(data, dataset_key)
            logger.info(f"✅ Analysis complete for {dataset_key}")

            # Power Mapping Prompts for NYPD and MTA
            if dataset_key == "police_incidents":
                nypd_power_prompt = create_nypd_power_mapping_prompt(analysis)
                nypd_power_mapping = call_claude_api(nypd_power_prompt)
                save_content(nypd_power_mapping, 'nyc-power-mapping', 'police_incidents')
            elif dataset_key == "mta_ridership":
                mta_power_prompt = create_mta_power_mapping_prompt(analysis)
                mta_power_mapping = call_claude_api(mta_power_prompt)
                save_content(mta_power_mapping, 'nyc-power-mapping', 'mta_ridership')

            # Save raw analysis always
            analysis_filename = f'drafts/raw-data-analysis/{datetime.now().strftime("%Y%m%d")}-{dataset_key}-analysis.json'
            os.makedirs('drafts/raw-data-analysis', exist_ok=True)
            with open(analysis_filename, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, indent=2, default=str)
            logger.info(f"💾 Saved raw analysis: {analysis_filename}")
            processed_count += 1
        except Exception as e:
            logger.error(f"Error processing {dataset_key}: {e}")
            continue
    logger.info(f"\n🎉 NYC data analysis complete! Processed {processed_count} datasets.")

if __name__ == "__main__":
    main()
